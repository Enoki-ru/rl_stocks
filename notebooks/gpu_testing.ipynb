{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97536866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üíª –°–∏—Å—Ç–µ–º–Ω–∞—è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ---\n",
      "OS: Darwin 25.2.0 (arm64)\n",
      "Python: 3.11.9\n",
      "------------------------------\n",
      "\n",
      "--- üî• PyTorch –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ---\n",
      "Version: 2.9.1\n",
      "CUDA Available: False\n",
      "MPS (Apple Silicon) Available: True\n",
      "‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ [MPS] —É—Å–ø–µ—à–Ω—ã.\n",
      "\n",
      "--- ‚ùÑÔ∏è TensorFlow –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ---\n",
      "Version: 2.15.0\n",
      "Physical GPUs: 1\n",
      "  - GPU 0: /physical_device:GPU:0 (GPU)\n",
      "Metal Acceleration: Active\n",
      "‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU —É—Å–ø–µ—à–Ω—ã.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 01:39:13.798595: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-12-27 01:39:13.798609: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-12-27 01:39:13.798611: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.72 GB\n",
      "2025-12-27 01:39:13.798651: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-12-27 01:39:13.798679: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_platform_info():\n",
    "    print(f\"--- üíª –°–∏—Å—Ç–µ–º–Ω–∞—è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ---\")\n",
    "    print(f\"OS: {platform.system()} {platform.release()} ({platform.machine()})\")\n",
    "    print(f\"Python: {sys.version.split()[0]}\")\n",
    "    print(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "def check_pytorch():\n",
    "    print(\"--- üî• PyTorch –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ---\")\n",
    "    print(f\"Version: {torch.__version__}\")\n",
    "    \n",
    "    # CUDA Check\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA Available: {cuda_available}\")\n",
    "    if cuda_available:\n",
    "        print(f\"  - Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  - CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"  - cuDNN: {torch.backends.cudnn.version()}\")\n",
    "    \n",
    "    # MPS Check (Apple Silicon)\n",
    "    mps_available = False\n",
    "    if platform.system() == \"Darwin\":\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ torch\n",
    "        mps_available = getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available()\n",
    "        print(f\"MPS (Apple Silicon) Available: {mps_available}\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç–æ–≤–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ\n",
    "    device_type = \"cuda\" if cuda_available else (\"mps\" if mps_available else \"cpu\")\n",
    "    device = torch.device(device_type)\n",
    "    \n",
    "    try:\n",
    "        x = torch.randn(2000, 2000, device=device)\n",
    "        _ = torch.mm(x, x.t())\n",
    "        print(f\"‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ [{device_type.upper()}] —É—Å–ø–µ—à–Ω—ã.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ {device_type}: {e}\")\n",
    "    print()\n",
    "\n",
    "def check_tensorflow():\n",
    "    print(\"--- ‚ùÑÔ∏è TensorFlow –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ---\")\n",
    "    print(f\"Version: {tf.__version__}\")\n",
    "    \n",
    "    # –û–±—â–∏–π —Å–ø–∏—Å–æ–∫ GPU\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"Physical GPUs: {len(physical_devices)}\")\n",
    "    for i, dev in enumerate(physical_devices):\n",
    "        print(f\"  - GPU {i}: {dev.name} ({dev.device_type})\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ Metal (–¥–ª—è macOS)\n",
    "    if platform.system() == \"Darwin\":\n",
    "        # –í TF 2.x –¥–ª—è Mac –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–ª–∞–≥–∏–Ω tensorflow-metal\n",
    "        is_metal = any(\"GPU\" in dev.device_type for dev in physical_devices)\n",
    "        print(f\"Metal Acceleration: {'Active' if is_metal else 'Not Found'}\")\n",
    "\n",
    "    # –¢–µ—Å—Ç–æ–≤–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ\n",
    "    try:\n",
    "        with tf.device('/GPU:0' if physical_devices else '/CPU:0'):\n",
    "            a = tf.random.normal([2000, 2000])\n",
    "            b = tf.matmul(a, tf.transpose(a))\n",
    "            print(f\"‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ {'GPU' if physical_devices else 'CPU'} —É—Å–ø–µ—à–Ω—ã.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π TF: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_platform_info()\n",
    "    check_pytorch()\n",
    "    check_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6877a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-torch env",
   "language": "python",
   "name": "project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
